{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment8_Berger_Bündert_Schwarzer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gq4MCZ0rRr_l",
        "WkVpQlzHnzKG",
        "bAZJjnoZQTPW"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq4MCZ0rRr_l"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TNwy5q3MQqi"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from tqdm import tqdm\n",
        "\n",
        "data = np.load('DataFeatSel.npy', allow_pickle = True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-wKXcVkJBBJ"
      },
      "source": [
        "X_train = list(data.values())[0]\n",
        "Y_train = list(data.values())[1]\n",
        "Y_test = list(data.values())[2]\n",
        "X_test = list(data.values())[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkVpQlzHnzKG"
      },
      "source": [
        "# **Exercise 14**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghZYgWYrWjJ-"
      },
      "source": [
        "def CrossValidationLS(X, Y, features):\n",
        "    ''' \n",
        "    function to conduct five-fold cross validation using least squares &\n",
        "    only the selected features\n",
        "\n",
        "    X, Y: training data\n",
        "    features: indices indicating the features under consideration\n",
        "\n",
        "    final_loss: average loss across all folds\n",
        "    '''\n",
        "\n",
        "    n = X.shape[0]\n",
        "    ind_fold = n/5\n",
        "    loss = []\n",
        "\n",
        "    X = X[:, features]\n",
        "    \n",
        "    for i in range(1,6): # 5-fold cross validation\n",
        "      loss_fold = 0\n",
        "\n",
        "      ind_val = np.arange((i-1)*ind_fold, i*ind_fold).astype(int)\n",
        "      ind_train = np.array([ind for ind in range(n) if ind not in ind_val]).astype(int)\n",
        "\n",
        "      Xval, Xtrain = X[ind_val], X[ind_train]\n",
        "      Yval, Ytrain = Y[ind_val], Y[ind_train]\n",
        "\n",
        "      # compute w\n",
        "      w = np.linalg.solve(Xtrain.T@Xtrain, Xtrain.T@Ytrain)\n",
        "\n",
        "      loss_fold = 1/2*np.absolute(Yval-np.sign(Xval@w))\n",
        "      loss.append(np.sum(loss_fold))\n",
        "\n",
        "    final_loss = np.sum(loss) / n\n",
        "    return final_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1McRcMawzxQ"
      },
      "source": [
        "def powerset(s):\n",
        "    ''' \n",
        "    function to compute all subsets of the set s\n",
        "    '''\n",
        "\n",
        "    x = len(s)\n",
        "    masks = [1 << i for i in range(x)]\n",
        "    for i in range(1, 1 << x):\n",
        "        yield [ss for mask, ss in zip(masks, s) if i & mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq8qCMM5-JCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf1bb19-460b-4b93-d782-c92447a42f69"
      },
      "source": [
        "# use cross-validation to determine best feature subset among all of them\n",
        "\n",
        "subsets = list(powerset(list(range(X_train.shape[1])))) # construct all subsets\n",
        "CVErrors = np.zeros([len(subsets), 1])\n",
        "\n",
        "for i in tqdm(range(len(subsets))):\n",
        "  CVErrors[i] = CrossValidationLS(X_train, Y_train, subsets[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 32767/32767 [01:05<00:00, 497.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loQXAtlR2DP3",
        "outputId": "4d15c57c-3a6c-406f-fe5f-75b6f742ece0"
      },
      "source": [
        "# report lowest error and best subset as well as error on test set if only\n",
        "# include those features\n",
        "\n",
        "best_subsets = np.where(CVErrors == min(CVErrors))\n",
        "\n",
        "for i in range(len(best_subsets[0])):\n",
        "  best_subset = subsets[best_subsets[0][i]]\n",
        "  print('Best feature subset:', best_subset, 'with CV error:', CVErrors[best_subsets[0][i]])\n",
        "\n",
        "  X_train_subset = X_train[:, best_subset]\n",
        "  w_subset = np.linalg.solve(X_train_subset.T@X_train_subset, X_train_subset.T@Y_train)\n",
        "\n",
        "  # evaluate the performance of the classifier(s)\n",
        "  X_test_subset = X_test[:, best_subset]\n",
        "  loss_test = 1/2*np.absolute(Y_test-np.sign(X_test_subset@w_subset))\n",
        "  print('Error on test set:', np.sum(loss_test)/X_test_subset.shape[0], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best feature subset: [3, 8, 9] with CV error: [0.2]\n",
            "Error on test set: 0.497 \n",
            "\n",
            "Best feature subset: [3, 9, 10] with CV error: [0.2]\n",
            "Error on test set: 0.502 \n",
            "\n",
            "Best feature subset: [3, 9, 10, 11] with CV error: [0.2]\n",
            "Error on test set: 0.504 \n",
            "\n",
            "Best feature subset: [3, 8, 9, 10, 13] with CV error: [0.2]\n",
            "Error on test set: 0.504 \n",
            "\n",
            "Best feature subset: [3, 4, 8, 9, 11, 13] with CV error: [0.2]\n",
            "Error on test set: 0.478 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7WFptGg242h"
      },
      "source": [
        "**Do you have an idea why the cross-validation error obtained in a) and the just computed test error are so different? Does this have to do with the classifier or the feature selection ? What will you tell the biologists ?**\n",
        "\n",
        "The test errors are significantly higher than the cross-validation errors obtained in a) for all of the best feature subsets. This is probably because of the feature selection and not because of the classifier as the best subsets were only the best ones for the training data but not for the problem at hand. Hence, overfitting took place as the selected features work well for the training data, but do not generalize to unseen data (test data). \n",
        "This is the also the case because we have a small training set (40 observations) in contrast to a large test set (1000 observations).\n",
        "\n",
        "Accordingly, one should tell the biologists that using only the smallest best subset without verifying its accuracy on an independent dataset is a bad idea and they should pursue this subset approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAZJjnoZQTPW"
      },
      "source": [
        "# **Exercise 15**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8t8qAJe54pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7507b65e-40ea-40d7-c9b9-c500477eea32"
      },
      "source": [
        "subsets = list(powerset(list(range(6)))) # construct subsets for first 6 features\n",
        "CVErrors = np.zeros([len(subsets), 1])\n",
        "\n",
        "# determine original test statistic\n",
        "for i in tqdm(range(len(subsets))):\n",
        "  CVErrors[i] = CrossValidationLS(X_train, Y_train, subsets[i])\n",
        "\n",
        "t = np.min(CVErrors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 63/63 [00:00<00:00, 884.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFxdzGcj6VMQ",
        "outputId": "11d22edd-1df8-4486-8dfc-e67af15b7be8"
      },
      "source": [
        "# compute test statistics for permuted labels\n",
        "\n",
        "test_statistics = []\n",
        "np.random.seed(1)\n",
        "for i in tqdm(range(1000)):\n",
        "  CVErrors = np.zeros([len(subsets), 1])\n",
        "  Y_train_permut = np.random.permutation(Y_train)\n",
        "\n",
        "  for i in range(len(subsets)):\n",
        "    CVErrors[i] = CrossValidationLS(X_train, Y_train_permut, subsets[i])\n",
        "\n",
        "  test_statistics.append(np.min(CVErrors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:12<00:00, 13.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "HbibSCoL5ECO",
        "outputId": "00a78b84-509b-477b-ce39-92a34114f5ed"
      },
      "source": [
        "plt.hist(test_statistics, 50);\n",
        "\n",
        "print(\"Rejection region = (-∞, {}]\".format(np.around(np.quantile(test_statistics, 0.05), 2)))\n",
        "print(\"Original test statistic = {}\".format(t))\n",
        "print(\"Approximate p-value = {} \\n\".format(np.around((test_statistics < t).sum()/len(test_statistics), 4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rejection region = (-∞, 0.25]\n",
            "Original test statistic = 0.325\n",
            "Approximate p-value = 0.303 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARgElEQVR4nO3df4zkdX3H8eeroDb1R4SyJQQ4F8hpA8YeuqGkFoNFK0IVrQ2VtgqKnjaQ1khST2yqsTGlKlqNFnMqERNFqIjSgFZKRGLSsy6IcKDIgUe8y3msYMQWSwu8+8d+V4d19m52Z2Z3+NzzkUz2O5/v9zvz8svNK1+/3+/MN1WFJKktv7bWASRJo2e5S1KDLHdJapDlLkkNstwlqUH7r3UAgIMOOqimp6fXOoYkPa7ceOONP66qqX7zJqLcp6enmZ2dXesYkvS4kuSepeZ5WEaSGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1aK/lnuTwJF9LcnuS25L8dTd+YJJrk9zZ/T2gG0+SDyfZluSWJM8d9/8ISdJjDbLn/jBwXlUdDRwPnJPkaGATcF1VrQeu654DvBRY3z02AheNPLUkaY/2Wu5VtauqbuqmfwZ8FzgUOA24pFvsEuAV3fRpwKdr3hbg6UkOGXlySdKSlvUN1STTwLHAN4GDq2pXN+tHwMHd9KHAD3tW29GN7eoZI8lG5vfsWbdu3TJjSys3venqvuPbLzh1lZNI4zPwCdUkTwGuAN5SVQ/0zqv52zkt65ZOVbW5qmaqamZqqu9PI0iSVmigck/yBOaL/TNV9YVuePfC4Zbu773d+E7g8J7VD+vGJEmrZJCrZQJ8EvhuVX2gZ9ZVwJnd9JnAl3rGX9tdNXM88NOewzeSpFUwyDH35wOvAW5NcnM3dj5wAXB5krOBe4DTu3nXAKcA24AHgdeNNLEkaa/2Wu5V9Q0gS8w+qc/yBZwzZC5J0hD8hqokNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGD3Gbv4iT3JtnaM3ZZkpu7x/aFOzQlmU7y8555HxtneElSf4PcZu9TwEeATy8MVNWfLkwnuRD4ac/yd1XVhlEFlCQt3yC32bshyXS/ed3Ns08H/mC0sSRJwxj2mPsJwO6qurNn7Igk307y9SQnDPn6kqQVGOSwzJ6cAVza83wXsK6q7kvyPOCLSY6pqgcWr5hkI7ARYN26dUPGkCT1WvGee5L9gT8GLlsYq6qHquq+bvpG4C7gmf3Wr6rNVTVTVTNTU1MrjSFJ6mOYwzIvAr5XVTsWBpJMJdmvmz4SWA/cPVxESdJyDXIp5KXAfwDPSrIjydndrFfz2EMyAC8Abukujfw88Oaqun+UgSVJezfI1TJnLDF+Vp+xK4Arho8lSRqG31CVpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBg1ym72Lk9ybZGvP2LuS7Exyc/c4pWfe25NsS3JHkpeMK7gkaWmD7Ll/Cji5z/gHq2pD97gGIMnRzN9b9ZhunX9euGG2JGn17LXcq+oGYNCbXJ8GfK6qHqqqHwDbgOOGyCdJWoG93iB7D85N8lpgFjivqn4CHAps6VlmRzf2K5JsBDYCrFu3bogYmgTTm67uO779glMfF68vtWalJ1QvAo4CNgC7gAuX+wJVtbmqZqpqZmpqaoUxJEn9rKjcq2p3VT1SVY8CH+eXh152Aof3LHpYNyZJWkUrKvckh/Q8fSWwcCXNVcCrkzwpyRHAeuA/h4soSVquvR5zT3IpcCJwUJIdwDuBE5NsAArYDrwJoKpuS3I5cDvwMHBOVT0ynujS2vI8gCbZXsu9qs7oM/zJPSz/HuA9w4SSJA3Hb6hKUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSg/Za7kkuTnJvkq09Y+9L8r0ktyS5MsnTu/HpJD9PcnP3+Ng4w0uS+htkz/1TwMmLxq4Fnl1VzwG+D7y9Z95dVbWhe7x5NDElScux13KvqhuA+xeNfbWqHu6ebgEOG0M2SdIKjeKY++uBL/c8PyLJt5N8PckJS62UZGOS2SSzc3NzI4ghSVqw/zArJ3kH8DDwmW5oF7Cuqu5L8jzgi0mOqaoHFq9bVZuBzQAzMzM1TA6pRdObru47vv2CU1c5iR6PVrznnuQs4I+AP6+qAqiqh6rqvm76RuAu4JkjyClJWoYVlXuSk4G/AV5eVQ/2jE8l2a+bPhJYD9w9iqCSpMHt9bBMkkuBE4GDkuwA3sn81TFPAq5NArCluzLmBcC7k/wf8Cjw5qq6v+8LS5LGZq/lXlVn9Bn+5BLLXgFcMWwoSdJw/IaqJDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNWigck9ycZJ7k2ztGTswybVJ7uz+HtCNJ8mHk2xLckuS544rvCSpv0H33D8FnLxobBNwXVWtB67rngO8lPkbY68HNgIXDR9TkrQcA5V7Vd0ALL7R9WnAJd30JcAresY/XfO2AE9PcsgowkqSBjPMMfeDq2pXN/0j4OBu+lDghz3L7ejGHiPJxiSzSWbn5uaGiCFJWmwkJ1SrqoBa5jqbq2qmqmampqZGEUOS1Bmm3HcvHG7p/t7bje8EDu9Z7rBuTJK0SoYp96uAM7vpM4Ev9Yy/trtq5njgpz2HbyRJq2D/QRZKcilwInBQkh3AO4ELgMuTnA3cA5zeLX4NcAqwDXgQeN2IM0uS9mKgcq+qM5aYdVKfZQs4Z5hQkqTh+A1VSWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJatBAd2LqJ8mzgMt6ho4E/g54OvBGYK4bP7+qrllxQknSsq243KvqDmADQJL9gJ3AlczfM/WDVfX+kSTUWE1vurrv+PYLTl3lJJJGaVSHZU4C7qqqe0b0epKkIYyq3F8NXNrz/NwktyS5OMkB/VZIsjHJbJLZubm5fotIklZo6HJP8kTg5cC/dEMXAUcxf8hmF3Bhv/WqanNVzVTVzNTU1LAxJEk9RrHn/lLgpqraDVBVu6vqkap6FPg4cNwI3kOStAyjKPcz6Dkkk+SQnnmvBLaO4D0kScuw4qtlAJI8GXgx8Kae4fcm2QAUsH3RPEnSKhiq3Kvqv4HfXDT2mqESSZKG5jdUJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUFD3YkJIMl24GfAI8DDVTWT5EDgMmCa+VvtnV5VPxn2vSRJgxnVnvsLq2pDVc10zzcB11XVeuC67rkkaZUMvee+hNOAE7vpS4DrgbeN6b32OdObrl5y3vYLTl3FJJIm1Sj23Av4apIbk2zsxg6uql3d9I+AgxevlGRjktkks3NzcyOIIUlaMIo999+vqp1Jfgu4Nsn3emdWVSWpxStV1WZgM8DMzMyvzJckrdzQe+5VtbP7ey9wJXAcsDvJIQDd33uHfR9J0uCGKvckT07y1IVp4A+BrcBVwJndYmcCXxrmfSRJyzPsYZmDgSuTLLzWZ6vqK0m+BVye5GzgHuD0Id9HkrQMQ5V7Vd0N/E6f8fuAk4Z5bUnSyvkNVUlqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNGtfNOiRNCG/usm9yz12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1aMWXQiY5HPg087faK2BzVX0oybuANwJz3aLnV9U1wwaVtPaWuqzSSyonzzDXuT8MnFdVN3U3yb4xybXdvA9W1fuHjydJWokVl3tV7QJ2ddM/S/Jd4NBRBZMkrdxIjrknmQaOBb7ZDZ2b5JYkFyc5YIl1NiaZTTI7NzfXbxFJ0goNXe5JngJcAbylqh4ALgKOAjYwv2d/Yb/1qmpzVc1U1czU1NSwMSRJPYYq9yRPYL7YP1NVXwCoqt1V9UhVPQp8HDhu+JiSpOVYcbknCfBJ4LtV9YGe8UN6FnslsHXl8SRJKzHM1TLPB14D3Jrk5m7sfOCMJBuYvzxyO/CmoRJKkpZtmKtlvgGkzyyvaZekNeY3VCWpQd6sYwz8Fp+kteaeuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIa5A+HSVp1/rje+LnnLkkNcs+9h3sTUhv8LI+x3JOcDHwI2A/4RFVdMK738j+kJD3WWMo9yX7AR4EXAzuAbyW5qqpuH8f7SdKkW+2d0HHtuR8HbKuquwGSfA44DbDcJT2uPF6PDKSqRv+iyZ8AJ1fVG7rnrwF+t6rO7VlmI7Cxe/os4I6RB1m5g4Afr3WIPZj0fGDGUZj0fDD5GSc9HwyX8RlVNdVvxpqdUK2qzcDmtXr/PUkyW1Uza51jKZOeD8w4CpOeDyY/46Tng/FlHNelkDuBw3ueH9aNSZJWwbjK/VvA+iRHJHki8GrgqjG9lyRpkbEclqmqh5OcC/wb85dCXlxVt43jvcZkIg8X9Zj0fGDGUZj0fDD5GSc9H4wp41hOqEqS1pY/PyBJDbLcJalB+1S5Jzk5yR1JtiXZ1Gf+W5PcnuSWJNcleUbPvDOT3Nk9zpzQjI8kubl7jO0E9gAZ35zk1i7HN5Ic3TPv7d16dyR5ySTlSzKd5Oc92/Bj48g3SMae5V6VpJLM9Iyt+TZcKt8kbcMkZyWZ68nyhp55Y/88D5lv+M9yVe0TD+ZP7N4FHAk8EfgOcPSiZV4I/EY3/ZfAZd30gcDd3d8DuukDJilj9/y/JmQ7Pq1n+uXAV7rpo7vlnwQc0b3OfhOUbxrYOgnbsFvuqcANwBZgZpK24R7yTcw2BM4CPtJn3bF/nofJ180b+rO8L+25/+InEarqf4GFn0T4har6WlU92D3dwvz1+QAvAa6tqvur6ifAtcDJE5ZxtQyS8YGep08GFs7anwZ8rqoeqqofANu615uUfKtlrxk7fw/8I/A/PWMTsQ33kG+1DJqxn9X4PA+TbyT2pXI/FPhhz/Md3dhSzga+vMJ1V2qYjAC/nmQ2yZYkrxhDPhgwY5JzktwFvBf4q+Wsu4b5AI5I8u0kX09ywoizDZwxyXOBw6tq8Q+bTMQ23EM+mJBt2HlVdwjz80kWvlg5EdtwD/lgBJ/lfancB5bkL4AZ4H1rnWUpS2R8Rs1/jfnPgH9KctSahAOq6qNVdRTwNuBv1yrHUpbItwtYV1XHAm8FPpvkaaudLcmvAR8Azlvt9x7EXvJNxDbs/CswXVXPYX7v/JI1yrGUPeUb+rO8L5X7QD+JkORFwDuAl1fVQ8tZd40zUlU7u793A9cDx65Vxh6fAxb2PFZjO644X3eo475u+kbmj5k+c8T5Bsn4VODZwPVJtgPHA1d1Jy0nYRsumW+CtiFVdV/P5+MTwPMGXXeN843mszzKkwiT/GD+27h3M38SauEExzGLljmW+X+M6xeNHwj8gPmTLwd00wdOWMYDgCd10wcBd9LnJNgqZVzfM/0yYLabPobHngy8m9GfDBwm39RCHuZPhO1cq//Oi5a/nl+esJyIbbiHfBOzDYFDeqZfCWzppsf+eR4y30g+yyPd4JP+AE4Bvt+V4zu6sXczvwcM8O/AbuDm7nFVz7qvZ/7k1TbgdZOWEfg94NbuH9GtwNlrmPFDwG1dvq/1/qNm/v9x3MX8Tzy/dJLyAa/qGb8JeNlabcNFy15PV56Tsg2XyjdJ2xD4hy7Ld7r/zr/ds+7YP88rzTeqz7I/PyBJDdqXjrlL0j7DcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkN+n+6Wg0Q/Ic6wwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlHFny0B73we"
      },
      "source": [
        "**What cross-validation error do you expect under the null hypothesis ?**\n",
        "\n",
        "Under the null hypothesis that features & labels are independent, a cross-validation error of 0.5 is expected. \n",
        "\n",
        "**Decision (reject/not reject the null hypothesis) *(written on paper)*. What does the result of the test imply for the result obtained in 14a) ?**\n",
        "\n",
        "Based on the p-value of 0.303 and the fact that the original test statistic lies not in the rejection region, the null hypothesis of independence between features and labels cannot be rejected. This goes hand in hand with the previously obtained result that the test error exceeds the CV error by far. The low CV errors might be due to fitting the idiosyncrasies of the training data, but not because of identifying a true relationship. Since the true relationship is not captured and might not even be able to be captured (because of the potential independence of X and Y), the test error is close to 0.5. The latter is as good as a random guess is expected to perform. Once again, it makes only  sense to train classifiers where inputs and outputs are related, which is not supported by the permutation test."
      ]
    }
  ]
}